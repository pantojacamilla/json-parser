    from bs4 import BeautifulSoup&#xD;&#xA;    from selenium import webdriver&#xD;&#xA;    import time&#xD;&#xA;    import urllib2&#xD;&#xA;    import unicodecsv as csv&#xD;&#xA;    import os&#xD;&#xA;    import sys&#xD;&#xA;    import io&#xD;&#xA;    import time&#xD;&#xA;    import datetime&#xD;&#xA;    import pandas as pd&#xD;&#xA;    from bs4 import BeautifulSoup&#xD;&#xA;    import re&#xD;&#xA;    import contextlib&#xD;&#xA;    import selenium.webdriver.support.ui as ui&#xD;&#xA;    filename=r'output.csv'&#xD;&#xA;    resultcsv=open(filename,"wb")&#xD;&#xA;    output=csv.writer(resultcsv, delimiter=';',quotechar = '"', quoting=csv.QUOTE_NONNUMERIC, encoding='latin-1')&#xD;&#xA;    output.writerow(['TIME','FLIGHT','FROM','AIRLANE','AIRCRAFT','STATUS','WHEREFROM', 'ACTUALDATE']) &#xD;&#xA;    def scrape(urls):&#xD;&#xA;        browser = webdriver.Firefox()&#xD;&#xA;        for url in urls:&#xD;&#xA;            browser.get(url)&#xD;&#xA;            html = browser.page_source&#xD;&#xA;            soup=BeautifulSoup(html,"html.parser")&#xD;&#xA;            table = soup.find('table', { "class" : "table table-condensed table-hover data-table m-n-t-15" })&#xD;&#xA;            soup2=BeautifulSoup(html,"html.parser")&#xD;&#xA;            name = soup2.find('div' , attrs={'class' : 'row m-t-l m-l-l'})&#xD;&#xA;            datatable=[]&#xD;&#xA;            for record in table.find_all('tr', class_="hidden-xs hidden-sm ng-scope"):&#xD;&#xA;                temp_data = []&#xD;&#xA;                for data in record.find_all("td"):&#xD;&#xA;                    temp_data.append(data.text.encode('latin-1'))&#xD;&#xA;                newlist = filter(None, temp_data)&#xD;&#xA;                datatable.append(newlist)&#xD;&#xA;            print name&#xD;&#xA;            output.writerows(datatable)&#xD;&#xA;        resultcsv.close()&#xD;&#xA;        time.sleep(10) &#xD;&#xA;        browser.close()&#xD;&#xA;        &#xD;&#xA;    urls = ["https://www.flightradar24.com/data/airports/bud/arrivals", "https://www.flightradar24.com/data/airports/fco/arrivals"]&#xD;&#xA;    scrape(urls)&#xD;&#xA;    resultcsv.close()